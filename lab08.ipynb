{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Contreras GP/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-10-9 Python-3.11.2 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- RESULTADOS --\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/6: 2128x1200 1 bottle\n",
      "image 2/6: 415x738 1 car\n",
      "image 3/6: 526x526 1 clock\n",
      "image 4/6: 1260x1500 1 chair, 1 couch\n",
      "image 5/6: 3000x3000 1 bicycle\n",
      "image 6/6: 225x225 1 sports ball, 1 wine glass, 3 chairs\n",
      "Speed: 29.1ms pre-process, 493.3ms inference, 5.1ms NMS per image at shape (6, 3, 640, 640)\n",
      "Saved 6 images to \u001b[1mruns\\detect\\exp5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- RESULTADOS ESPECIFICOS POR IMAGEN --\n",
      "\n",
      "* Predicciones para la imagen 0:\n",
      "         xmin       ymin        xmax         ymax  confidence  class    name\n",
      "0  327.482239  52.133442  875.108398  2001.086304    0.824742     39  bottle\n",
      "\n",
      "\n",
      "* Predicciones para la imagen 1:\n",
      "        xmin        ymin        xmax        ymax  confidence  class name\n",
      "0  86.837898  119.625107  677.501831  334.025146    0.882365      2  car\n",
      "\n",
      "\n",
      "* Predicciones para la imagen 2:\n",
      "         xmin        ymin       xmax        ymax  confidence  class   name\n",
      "0  164.507004  161.367737  345.14566  335.545959    0.900749     74  clock\n",
      "\n",
      "\n",
      "* Predicciones para la imagen 3:\n",
      "        xmin       ymin         xmax         ymax  confidence  class   name\n",
      "0  72.691299  12.917045  1460.859863  1253.681519    0.358447     56  chair\n",
      "1  62.941429  27.138546  1417.901733  1254.323364    0.252937     57  couch\n",
      "\n",
      "\n",
      "* Predicciones para la imagen 4:\n",
      "         xmin        ymin         xmax         ymax  confidence  class  \\\n",
      "0  130.345062  167.458099  2912.029541  2740.075928    0.455927      1   \n",
      "\n",
      "      name  \n",
      "0  bicycle  \n",
      "\n",
      "\n",
      "* Predicciones para la imagen 5:\n",
      "         xmin       ymin        xmax        ymax  confidence  class  \\\n",
      "0  122.076569  62.761585  198.110352  174.667679    0.901594     56   \n",
      "1   26.923899  66.471924  111.760254  175.902527    0.800907     56   \n",
      "2   44.829880  56.443985   78.132385   72.677765    0.579786     56   \n",
      "3   97.009491  51.275444  120.179695   77.797340    0.292283     40   \n",
      "4  189.946960   3.132274  220.363251   20.969728    0.264185     32   \n",
      "\n",
      "          name  \n",
      "0        chair  \n",
      "1        chair  \n",
      "2        chair  \n",
      "3   wine glass  \n",
      "4  sports ball  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Recoverd from https://pytorch.org/hub/ultralytics_yolov5/\n",
    "\n",
    "# Images a evaluar \n",
    "imgs = ['.\\Objeto1.jpg','.\\Objeto2.jpg','.\\Objeto3.jpg','.\\Objeto4.jpg','.\\Objeto5.jpg','.\\Objeto6.jpg']\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "print(\"\\n-- RESULTADOS --\\n\")\n",
    "# Inference\n",
    "results = model(imgs)\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.save() \n",
    "\n",
    "\n",
    "print(\"\\n-- RESULTADOS ESPECIFICOS POR IMAGEN --\\n\")\n",
    "# Itera sobre las imágenes y los resultados\n",
    "for i in range(len(imgs)):\n",
    "    img_path = imgs[i]  # Ruta de la imagen actual\n",
    "    img_predictions_df = results.pandas().xyxy[i] # Acceder a predicciones \n",
    "    \n",
    "    # Imprime las predicciones como DataFrame\n",
    "    print(f\"* Predicciones para la imagen {i}:\")\n",
    "    print(img_predictions_df)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Contreras GP\\Documents\\GitHub\\Lab08-DL\\lab08.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Contreras%20GP/Documents/GitHub/Lab08-DL/lab08.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m video_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./pt2.mp4\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Contreras%20GP/Documents/GitHub/Lab08-DL/lab08.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Abre el archivo de video\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Contreras%20GP/Documents/GitHub/Lab08-DL/lab08.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(video_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Contreras%20GP/Documents/GitHub/Lab08-DL/lab08.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Contreras%20GP/Documents/GitHub/Lab08-DL/lab08.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Ruta al video que deseas procesar\n",
    "video_path = './pt2.mp4'\n",
    "\n",
    "# Abre el archivo de video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Realiza la inferencia en el fotograma actual\n",
    "    results = model(frame)\n",
    "\n",
    "    # Dibuja las predicciones en el fotograma (puedes personalizar esto según tus necesidades)\n",
    "    annotated_frame = results.render()[0]\n",
    "\n",
    "    # Muestra el fotograma con las detecciones\n",
    "    display(Image(data=annotated_frame))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
